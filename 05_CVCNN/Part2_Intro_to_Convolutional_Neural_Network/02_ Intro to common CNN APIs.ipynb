{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "639ced3c-8592-4bc2-bdab-36a101180bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 下載並解壓縮課程所需檔案\n",
    "!wget \"https://github.com/TA-aiacademy/course_3.0/releases/download/CVCNN_Data/cnn_part2_data.zip\"\n",
    "!unzip cnn_part2_data.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d15cb23",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Intro to common CNN APIs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc997fd7",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 本章節大綱\n",
    "* [Conv2D( filters, kernel_size, strides, use_bias)](#Conv2D)\n",
    "  * [use_bias](#use-bias)\n",
    "  * [Multi-Channels](#Multi-Channels-with-1-Filter)\n",
    "  * [filters](#filters)\n",
    "  * [kernel_size](#kernel-_-size)\n",
    "  * [strides](#strides)\n",
    "* [Flatten](#Flatten)\n",
    "* [Padding](#Padding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd324596",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.keras.layers import Conv2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1423ee4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_img = np.array([[0, 0, 0, 0, 0, 0],\n",
    "                      [0, 0, 0, 1, 1, 0],\n",
    "                      [0, 1, 1, 1, 1, 0],\n",
    "                      [0, 0, 1, 0, 1, 0],\n",
    "                      [0, 0, 0, 1, 0, 0],\n",
    "                      [0, 0, 0, 0, 0, 0]], dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3390834",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce9837c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_img = input_img[np.newaxis, ..., np.newaxis]\n",
    "print(input_img.shape)\n",
    "print(\"(batch_size, height, width, channel)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "673694f8",
   "metadata": {},
   "source": [
    "* ## Conv2D\n",
    "![](https://i.imgur.com/ziscEhS.gif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5149f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kernel_init(shape, dtype=None):\n",
    "    filter_init = np.array([[1, 0, 0], [0, 1, 0], [0, 0, 1]], dtype='float32')\n",
    "    # height, width, channel, filters\n",
    "    filter_init = filter_init.reshape((3, 3, 1, 1))\n",
    "    return tf.Variable(filter_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5637240e",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_result = Conv2D(filters=1, kernel_size=(3, 3), strides=(1, 1),\n",
    "                     kernel_initializer=kernel_init)(input_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0a5ae02",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_result = conv_result.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f50575a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "865377f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(conv_result.shape)\n",
    "print(conv_result.squeeze())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b84d1150",
   "metadata": {},
   "source": [
    "[(back...)](#Convolution2D)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a0a1679",
   "metadata": {},
   "source": [
    "* ## use bias\n",
    "![](https://i.imgur.com/3x4wMGO.gif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ae93884",
   "metadata": {},
   "outputs": [],
   "source": [
    "bias_result = Conv2D(filters=1, kernel_size=(3, 3), strides=(1, 1),\n",
    "                     kernel_initializer=kernel_init,\n",
    "                     use_bias=True,\n",
    "                     bias_initializer='ones')(input_img)\n",
    "\n",
    "bias_result = bias_result.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb15c6a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(bias_result.shape)\n",
    "print(bias_result.squeeze())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0910de2",
   "metadata": {},
   "source": [
    "[(back...)](#Convolution2D)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4abe2b13",
   "metadata": {},
   "source": [
    "* ## Multi Channels with 1 Filter\n",
    "![](https://i.imgur.com/NCivRaq.gif)\n",
    "![](https://i.imgur.com/QEjI0jq.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5ae2339",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_img = np.load(\"./data/conv2d_multichannel_input.npy\")\n",
    "print(input_img.shape)\n",
    "print(input_img.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b474bac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_img = input_img[np.newaxis, ...]\n",
    "print(input_img.shape)\n",
    "print(\"(Batch_size, Height, Width, Channel)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5dd8c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_img = input_img.astype(\"float32\")\n",
    "print(input_img.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc9e2e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_init = np.load(\"./data/conv2d_multichannelfilter.npy\")\n",
    "print(filter_init.shape)\n",
    "print(\"(Height, Width, Channel, Num of Filters)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "659c2e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_init = tf.constant_initializer(filter_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fa54276",
   "metadata": {},
   "outputs": [],
   "source": [
    "multichannel = Conv2D(filters=1, kernel_size=(3, 3), strides=(1, 1),\n",
    "                      kernel_initializer=kernel_init)(input_img)\n",
    "\n",
    "multichannel = multichannel.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94e054a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(multichannel.shape)\n",
    "print(multichannel.squeeze())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c8264f6",
   "metadata": {},
   "source": [
    "[(back...)](#Convolution2D)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8804a8b9",
   "metadata": {},
   "source": [
    "* ## filters\n",
    "![](https://i.imgur.com/NCivRaq.gif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7e78bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_filter_init = np.zeros((3, 3, 3, 8))\n",
    "for i in range(8):\n",
    "    multi_filter_init[:, :, :, i] = filter_init.squeeze()\n",
    "multi_filter_init = multi_filter_init.astype('float32')\n",
    "\n",
    "print(multi_filter_init.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "926c1350",
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_init = tf.constant_initializer(multi_filter_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96f3015f",
   "metadata": {},
   "outputs": [],
   "source": [
    "multifilter = Conv2D(8, (3, 3), strides=(1, 1),\n",
    "                     kernel_initializer=kernel_init)(input_img)\n",
    "\n",
    "multifilter = multifilter.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70739ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(multifilter.shape)\n",
    "print(multifilter.squeeze())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5c44b92",
   "metadata": {},
   "source": [
    "[(back...)](#Convolution2D)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "457111dc",
   "metadata": {},
   "source": [
    "* ## strides\n",
    "![](https://i.imgur.com/8XWHNqI.gif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aa9d54f",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_img = np.load(\"./data/conv2d_1channel_input.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d9939e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_init = np.array([[1, 0, 0], [0, 1, 0], [0, 0, 1]], dtype='float32')\n",
    "filter_init = filter_init.reshape((3, 3, 1, 1))\n",
    "kernel_init = tf.constant_initializer(filter_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "118f67b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "stride_result = Conv2D(1, (3, 3), strides=(2, 2),\n",
    "                       kernel_initializer=kernel_init)(input_img)\n",
    "\n",
    "stride_result = stride_result.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a0e4155",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(stride_result.shape)\n",
    "print(stride_result.squeeze())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "549a4128",
   "metadata": {},
   "source": [
    "![](https://i.imgur.com/2XmNAct.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98d6bf69",
   "metadata": {},
   "source": [
    "# Flatten\n",
    "\n",
    "### Function API\n",
    "* [Way1-Reshape](#Way1---Reshape)\n",
    "* [Way2-Flatten](#Way2---Flatten)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1affbcd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.layers import Flatten, Reshape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a811d55b",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_img1 = np.array([[0, 1, 2, 3],\n",
    "                       [4, 5, 6, 7],\n",
    "                       [8, 9, 10, 11],\n",
    "                       [12, 13, 14, 15]], dtype='float32')\n",
    "input_img1 = input_img1[np.newaxis, ..., np.newaxis]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7a36ca8",
   "metadata": {},
   "source": [
    "* ## Way1 - Reshape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0011082",
   "metadata": {},
   "outputs": [],
   "source": [
    "reshape_result = Reshape(target_shape=(-1,))(input_img1)\n",
    "reshape_result = reshape_result.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1001ee83",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(input_img1.shape)\n",
    "print(reshape_result.shape)\n",
    "print(reshape_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "465fa3a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_img2 = input_img1.copy()\n",
    "for _ in range(3):\n",
    "    input_img2 = np.concatenate([input_img2, input_img2], -1)\n",
    "\n",
    "print(input_img2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bbe160f",
   "metadata": {},
   "outputs": [],
   "source": [
    "reshape_result = Reshape(target_shape=(-1,))(input_img2)\n",
    "reshape_result = reshape_result.numpy()\n",
    "print(reshape_result.shape)\n",
    "print(reshape_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "061c386f",
   "metadata": {},
   "source": [
    "[(back...)](#Flatten)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3862d61c",
   "metadata": {},
   "source": [
    "* ## Way2 - Flatten"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cfe20d1",
   "metadata": {},
   "source": [
    "![](https://i.imgur.com/MvwO4a0.gif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caf6afad",
   "metadata": {},
   "outputs": [],
   "source": [
    "flatten_result = Flatten()(input_img1)\n",
    "flatten_result = flatten_result.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2235b431",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(input_img1.shape)\n",
    "print(flatten_result.shape)\n",
    "print(flatten_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc5e5f71",
   "metadata": {},
   "source": [
    "![](https://i.imgur.com/FDh4d0L.gif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d590a27a",
   "metadata": {},
   "outputs": [],
   "source": [
    "flatten_result = Flatten()(input_img2)\n",
    "flatten_result = flatten_result.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5563aaff",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(flatten_result.shape)\n",
    "print(flatten_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88830829",
   "metadata": {},
   "source": [
    "[(back...)](#Flatten)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be96922a",
   "metadata": {},
   "source": [
    "# Padding\n",
    "\n",
    "### Functional API\n",
    "* [padding='VALID'](#padding='VALID')\n",
    "* [padding='SAME'](#padding='SAME')\n",
    "* [ZeroPadding](#ZeroPadding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bb5f523",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.keras.layers import Conv2D, ZeroPadding2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36517470",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_img = np.array([[0, 0, 0, 0, 0, 0],\n",
    "                      [0, 0, 0, 1, 1, 0],\n",
    "                      [0, 1, 1, 1, 1, 0],\n",
    "                      [0, 0, 1, 0, 1, 0],\n",
    "                      [0, 0, 0, 1, 0, 0],\n",
    "                      [0, 0, 0, 0, 0, 0]], dtype='float32')\n",
    "input_img = input_img[np.newaxis, ..., np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0168386",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kernel_init(shape, dtype=None):\n",
    "    filter_init = np.array([[1, 0, 0], [0, 1, 0], [0, 0, 1]])\n",
    "    filter_init = filter_init.reshape((3, 3, 1, 1))\n",
    "    return tf.Variable(filter_init, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "627d3504",
   "metadata": {},
   "source": [
    "* ## padding='VALID'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c928cc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "nopad_result = Conv2D(1, (3, 3), padding='VALID',\n",
    "                      kernel_initializer=kernel_init)(input_img)\n",
    "\n",
    "nopad_result = nopad_result.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1498dc32",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(input_img.shape)\n",
    "print(nopad_result.shape)\n",
    "print(nopad_result.squeeze())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee922287",
   "metadata": {},
   "source": [
    "[(back...)](#Padding)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "725e093a",
   "metadata": {},
   "source": [
    "* ## padding='SAME'\n",
    "![](https://i.imgur.com/vZWnAvN.gif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80aa91e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pad_result = Conv2D(1, (3, 3), padding='SAME',\n",
    "                    kernel_initializer=kernel_init)(input_img)\n",
    "\n",
    "pad_result = pad_result.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4070f425",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(input_img.shape)\n",
    "print(pad_result.shape)\n",
    "print(pad_result.squeeze())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "099a95eb",
   "metadata": {},
   "source": [
    "[(back...)](#Padding)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8474d89",
   "metadata": {},
   "source": [
    "## ZeroPadding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39b798f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_padding = ZeroPadding2D(padding=(1, 1))(input_img)\n",
    "zero_result = Conv2D(1, (3, 3),\n",
    "                     kernel_initializer=kernel_init)(zero_padding)\n",
    "\n",
    "zero_padding = zero_padding.numpy()\n",
    "zero_result = zero_result.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b53baca",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(input_img.shape)\n",
    "print(zero_padding.shape)\n",
    "print(zero_padding.squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d83c092",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(zero_result.shape)\n",
    "print(zero_result.squeeze())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "608ee985",
   "metadata": {},
   "source": [
    "[(back...)](#Padding)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bf634ad",
   "metadata": {},
   "source": [
    "# Pooling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "317f9f04",
   "metadata": {},
   "source": [
    "### Functional API\n",
    "\n",
    "* [Average Pooling](#Average-Pooling)\n",
    "* [Max Pooling](#Max-Pooling)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65658d2c",
   "metadata": {},
   "source": [
    "![](https://i.imgur.com/XZQtZC3.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc20aa60",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.layers import AveragePooling2D, MaxPool2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d4401c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_img = np.array([[1, 2, 2, 0],\n",
    "                      [1, 2, 3, 2],\n",
    "                      [3, 1, 3, 2],\n",
    "                      [0, 2, 0, 2]], dtype='float32').reshape((1, 4, 4, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1be04cf",
   "metadata": {},
   "source": [
    "* ## Average Pooling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cddb6278",
   "metadata": {},
   "source": [
    "![](https://i.imgur.com/sDKe1To.gif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be6173e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_result = AveragePooling2D()(input_img)\n",
    "avg_result = avg_result.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5413c810",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(input_img.shape)\n",
    "print(avg_result.shape)\n",
    "print(avg_result.squeeze())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc21129e",
   "metadata": {},
   "source": [
    "[(back...)](#Pooling)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8259a912",
   "metadata": {},
   "source": [
    "* ## Max Pooling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9dd09f9",
   "metadata": {},
   "source": [
    "![](https://i.imgur.com/HZhzUzN.gif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4037c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_result = MaxPool2D()(input_img)\n",
    "max_result = max_result.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e43b7cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(input_img.shape)\n",
    "print(max_result.shape)\n",
    "print(max_result.squeeze())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb0122ee",
   "metadata": {},
   "source": [
    "[(back...)](#Pooling)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97baa446",
   "metadata": {},
   "source": [
    "# GlobalPooling\n",
    "\n",
    "### Functional API\n",
    "* [Global Average Pooling](#Global-Average-Pooling)\n",
    "* [Global Max Pooling](#Global-Max-Pooling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f1f43b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.layers import (GlobalAveragePooling2D,\n",
    "                                     GlobalMaxPooling2D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "266a3c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_img = np.load(\"./data/globalpooling_input.npy\")[np.newaxis, ...]\n",
    "input_img = input_img.astype('float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc461240",
   "metadata": {},
   "source": [
    "* ## Global Average Pooling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd7809a8",
   "metadata": {},
   "source": [
    "![](https://i.imgur.com/c62Vie8.gif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f9607ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(input_img.shape)\n",
    "print(input_img[..., 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c986ce45",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_result = GlobalAveragePooling2D()(input_img)\n",
    "avg_result = avg_result.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b0f3221",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(avg_result.shape)\n",
    "print(avg_result.squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae8e0163",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_img.mean((1, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53cc4b72",
   "metadata": {},
   "source": [
    "[(back...)](#GlobalPooling)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5875e99",
   "metadata": {},
   "source": [
    "* ## Global Max Pooling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82a5c675",
   "metadata": {},
   "source": [
    "![](https://i.imgur.com/XFNnWSe.gif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca9f8365",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_result = GlobalMaxPooling2D()(input_img)\n",
    "max_result = max_result.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ec99682",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(input_img.shape)\n",
    "print(input_img[..., 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e3b3eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(max_result.shape)\n",
    "print(max_result.squeeze())\n",
    "# print(max_result[..., 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0355e34f",
   "metadata": {},
   "source": [
    "[(back...)](#GlobalPooling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c63a11a8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
