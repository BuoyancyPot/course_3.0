{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a1c57b29",
   "metadata": {
    "tags": []
   },
   "source": [
    "# **Intro to common CNN APIs**\n",
    "此份程式碼會介紹在 CNN model 當中常使用的 Layers。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a058c61b",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 本章節大綱\n",
    "* [Conv2D( filters, kernel_size, strides, use_bias)](#Conv2D)\n",
    "  * [use_bias](#use-bias)\n",
    "  * [Multi-Channels](#Multi-Channels-with-1-Filter)\n",
    "  * [filters](#filters)\n",
    "  * [kernel_size](#kernel-_-size)\n",
    "  * [strides](#strides)\n",
    "* [Flatten](#Flatten)\n",
    "* [Padding](#Padding)\n",
    "* [Pooling](#Pooling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc74803c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Conv2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "892a4649",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 下載並解壓縮課程所需檔案\n",
    "!wget -q \"https://github.com/TA-aiacademy/course_3.0/releases/download/CVCNN_Data/cnn_part2_data.zip\"\n",
    "!unzip -q cnn_part2_data.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa708110",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_img = np.array([[0, 0, 0, 0, 0, 0],\n",
    "                      [0, 0, 0, 1, 1, 0],\n",
    "                      [0, 1, 1, 1, 1, 0],\n",
    "                      [0, 0, 1, 0, 1, 0],\n",
    "                      [0, 0, 0, 1, 0, 0],\n",
    "                      [0, 0, 0, 0, 0, 0]], dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a20660c",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a129228",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_img = input_img[np.newaxis, ..., np.newaxis]\n",
    "print(input_img.shape)\n",
    "print(\"(batch_size, height, width, channel)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2db1e179",
   "metadata": {},
   "source": [
    "* ## Conv2D\n",
    "![](https://i.imgur.com/ziscEhS.gif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac88895b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kernel_init(shape, dtype=None):\n",
    "    filter_init = np.array([[1, 0, 0], [0, 1, 0], [0, 0, 1]], dtype='float32')\n",
    "    # height, width, channel, filters\n",
    "    filter_init = filter_init.reshape((3, 3, 1, 1))\n",
    "    return tf.Variable(filter_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b60508c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_result = Conv2D(filters=1, kernel_size=(3, 3), strides=(1, 1),\n",
    "                     kernel_initializer=kernel_init)(input_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e34df4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_result = conv_result.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10a10b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(conv_result.shape)\n",
    "print(conv_result.squeeze())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36e425de",
   "metadata": {},
   "source": [
    "[(back...)](#Convolution2D)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ababf5f4",
   "metadata": {},
   "source": [
    "* ## use bias\n",
    "![](https://i.imgur.com/3x4wMGO.gif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b11f6dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "bias_result = Conv2D(filters=1, kernel_size=(3, 3), strides=(1, 1),\n",
    "                     kernel_initializer=kernel_init,\n",
    "                     use_bias=True,\n",
    "                     bias_initializer='ones')(input_img)\n",
    "\n",
    "bias_result = bias_result.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0853dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(bias_result.shape)\n",
    "print(bias_result.squeeze())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e64f608a",
   "metadata": {},
   "source": [
    "[(back...)](#Convolution2D)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c99528bb",
   "metadata": {},
   "source": [
    "* ## Multi Channels with 1 Filter\n",
    "![](https://i.imgur.com/NCivRaq.gif)\n",
    "![](https://i.imgur.com/QEjI0jq.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "879a985d",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_img = np.load(\"./data/conv2d_multichannel_input.npy\")\n",
    "print(input_img.shape)\n",
    "print(input_img.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8151055",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_img = input_img[np.newaxis, ...]\n",
    "print(input_img.shape)\n",
    "print(\"(Batch_size, Height, Width, Channel)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c850023",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_img = input_img.astype(\"float32\")\n",
    "print(input_img.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "199b526e",
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_init = np.load(\"./data/conv2d_multichannelfilter.npy\")\n",
    "print(filter_init.shape)\n",
    "print(\"(Height, Width, Channel, Num of Filters)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96c55615",
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_init = tf.constant_initializer(filter_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e2793e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "multichannel = Conv2D(filters=1, kernel_size=(3, 3), strides=(1, 1),\n",
    "                      kernel_initializer=kernel_init)(input_img)\n",
    "\n",
    "multichannel = multichannel.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b2574da",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(multichannel.shape)\n",
    "print(multichannel.squeeze())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73b6d344",
   "metadata": {},
   "source": [
    "[(back...)](#Convolution2D)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1989115e",
   "metadata": {},
   "source": [
    "* ## filters\n",
    "![](https://i.imgur.com/NCivRaq.gif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38822754",
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_filter_init = np.zeros((3, 3, 3, 8))\n",
    "for i in range(8):\n",
    "    multi_filter_init[:, :, :, i] = filter_init.squeeze()\n",
    "multi_filter_init = multi_filter_init.astype('float32')\n",
    "\n",
    "print(multi_filter_init.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25469607",
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_init = tf.constant_initializer(multi_filter_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f67c5be",
   "metadata": {},
   "outputs": [],
   "source": [
    "multifilter = Conv2D(8, (3, 3), strides=(1, 1),\n",
    "                     kernel_initializer=kernel_init)(input_img)\n",
    "\n",
    "multifilter = multifilter.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "038abdd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(multifilter.shape)\n",
    "print(multifilter.squeeze())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a3ecdcc",
   "metadata": {},
   "source": [
    "[(back...)](#Convolution2D)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5780e5f",
   "metadata": {},
   "source": [
    "* ## strides\n",
    "![](https://i.imgur.com/8XWHNqI.gif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a20f90d",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_img = np.load(\"./data/conv2d_1channel_input.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b651f982",
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_init = np.array([[1, 0, 0], [0, 1, 0], [0, 0, 1]], dtype='float32')\n",
    "filter_init = filter_init.reshape((3, 3, 1, 1))\n",
    "kernel_init = tf.constant_initializer(filter_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0692e067",
   "metadata": {},
   "outputs": [],
   "source": [
    "stride_result = Conv2D(1, (3, 3), strides=(2, 2),\n",
    "                       kernel_initializer=kernel_init)(input_img)\n",
    "\n",
    "stride_result = stride_result.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f860f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(stride_result.shape)\n",
    "print(stride_result.squeeze())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1117dfb",
   "metadata": {},
   "source": [
    "![](https://i.imgur.com/2XmNAct.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "226ebc84",
   "metadata": {},
   "source": [
    "# Flatten\n",
    "\n",
    "* [Way1-Reshape](#Way1---Reshape)\n",
    "* [Way2-Flatten](#Way2---Flatten)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2123e052",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.layers import Flatten, Reshape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3d00cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_img1 = np.array([[0, 1, 2, 3],\n",
    "                       [4, 5, 6, 7],\n",
    "                       [8, 9, 10, 11],\n",
    "                       [12, 13, 14, 15]], dtype='float32')\n",
    "input_img1 = input_img1[np.newaxis, ..., np.newaxis]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "605b5482",
   "metadata": {},
   "source": [
    "* ## Way1 - Reshape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f6479ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "reshape_result = Reshape(target_shape=(-1,))(input_img1)\n",
    "reshape_result = reshape_result.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb9ad1b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(input_img1.shape)\n",
    "print(reshape_result.shape)\n",
    "print(reshape_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "520a029c",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_img2 = input_img1.copy()\n",
    "for _ in range(3):\n",
    "    input_img2 = np.concatenate([input_img2, input_img2], -1)\n",
    "print(input_img2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "748cc6cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "reshape_result = Reshape(target_shape=(-1,))(input_img2)\n",
    "reshape_result = reshape_result.numpy()\n",
    "print(reshape_result.shape)\n",
    "print(reshape_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14b890ab",
   "metadata": {},
   "source": [
    "[(back...)](#Flatten)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4d92754",
   "metadata": {},
   "source": [
    "* ## Way2 - Flatten"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20defa23",
   "metadata": {},
   "source": [
    "![](https://i.imgur.com/MvwO4a0.gif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f3c9d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "flatten_result = Flatten()(input_img1)\n",
    "flatten_result = flatten_result.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64333d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(input_img1.shape)\n",
    "print(flatten_result.shape)\n",
    "print(flatten_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a969f056",
   "metadata": {},
   "source": [
    "![](https://i.imgur.com/FDh4d0L.gif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dcc4f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "flatten_result = Flatten()(input_img2)\n",
    "flatten_result = flatten_result.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40f3801c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(flatten_result.shape)\n",
    "print(flatten_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff31296e",
   "metadata": {},
   "source": [
    "[(back...)](#Flatten)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "759db77b",
   "metadata": {},
   "source": [
    "# Padding\n",
    "\n",
    "* [padding='VALID'](#padding='VALID')\n",
    "* [padding='SAME'](#padding='SAME')\n",
    "* [ZeroPadding](#ZeroPadding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89094744",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Conv2D, ZeroPadding2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8ecf430",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_img = np.array([[0, 0, 0, 0, 0, 0],\n",
    "                      [0, 0, 0, 1, 1, 0],\n",
    "                      [0, 1, 1, 1, 1, 0],\n",
    "                      [0, 0, 1, 0, 1, 0],\n",
    "                      [0, 0, 0, 1, 0, 0],\n",
    "                      [0, 0, 0, 0, 0, 0]], dtype='float32')\n",
    "input_img = input_img[np.newaxis, ..., np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4c352fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kernel_init(shape, dtype=None):\n",
    "    filter_init = np.array([[1, 0, 0], [0, 1, 0], [0, 0, 1]])\n",
    "    filter_init = filter_init.reshape((3, 3, 1, 1))\n",
    "    return tf.Variable(filter_init, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d584cc59",
   "metadata": {},
   "source": [
    "* ## padding='VALID'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d306609f",
   "metadata": {},
   "outputs": [],
   "source": [
    "nopad_result = Conv2D(1, (3, 3), padding='VALID',\n",
    "                      kernel_initializer=kernel_init)(input_img)\n",
    "\n",
    "nopad_result = nopad_result.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91d6bb5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(input_img.shape)\n",
    "print(nopad_result.shape)\n",
    "print(nopad_result.squeeze())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1df004a7",
   "metadata": {},
   "source": [
    "[(back...)](#Padding)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f3930e8",
   "metadata": {},
   "source": [
    "* ## padding='SAME'\n",
    "![](https://i.imgur.com/vZWnAvN.gif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e4191de",
   "metadata": {},
   "outputs": [],
   "source": [
    "pad_result = Conv2D(1, (3, 3), padding='SAME',\n",
    "                    kernel_initializer=kernel_init)(input_img)\n",
    "\n",
    "pad_result = pad_result.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef6dc30f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(input_img.shape)\n",
    "print(pad_result.shape)\n",
    "print(pad_result.squeeze())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09817d37",
   "metadata": {},
   "source": [
    "[(back...)](#Padding)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d791cdd5",
   "metadata": {},
   "source": [
    "## ZeroPadding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bdd82dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_padding = ZeroPadding2D(padding=(1, 1))(input_img)\n",
    "zero_result = Conv2D(1, (3, 3),\n",
    "                     kernel_initializer=kernel_init)(zero_padding)\n",
    "\n",
    "zero_padding = zero_padding.numpy()\n",
    "zero_result = zero_result.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8855506",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(input_img.shape)\n",
    "print(zero_padding.shape)\n",
    "print(zero_result.shape)\n",
    "print(pad_result.squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3aa11a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(zero_result.shape)\n",
    "print(zero_result.squeeze())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "226a3799",
   "metadata": {},
   "source": [
    "[(back...)](#Padding)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a35b84c",
   "metadata": {},
   "source": [
    "# Pooling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3481d2e",
   "metadata": {},
   "source": [
    "\n",
    "* [Average Pooling](#Average-Pooling)\n",
    "* [Max Pooling](#Max-Pooling)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad611435",
   "metadata": {},
   "source": [
    "![](https://i.imgur.com/XZQtZC3.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "455afb33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.layers import AveragePooling2D, MaxPool2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f15fea17",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_img = np.array([[1, 2, 2, 0],\n",
    "                      [1, 2, 3, 2],\n",
    "                      [3, 1, 3, 2],\n",
    "                      [0, 2, 0, 2]], dtype='float32').reshape((1, 4, 4, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0d96d3b",
   "metadata": {},
   "source": [
    "* ## Average Pooling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0244b299",
   "metadata": {},
   "source": [
    "![](https://i.imgur.com/sDKe1To.gif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cc29176",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_result = AveragePooling2D()(input_img)\n",
    "avg_result = avg_result.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0de5ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(input_img.shape)\n",
    "print(avg_result.shape)\n",
    "print(avg_result.squeeze())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6d7242c",
   "metadata": {},
   "source": [
    "[(back...)](#Pooling)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d02f27a4",
   "metadata": {},
   "source": [
    "* ## Max Pooling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4303584b",
   "metadata": {},
   "source": [
    "![](https://i.imgur.com/HZhzUzN.gif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51db5f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_result = MaxPool2D()(input_img)\n",
    "max_result = max_result.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21cf68a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(input_img.shape)\n",
    "print(max_result.shape)\n",
    "print(max_result.squeeze())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "495865d7",
   "metadata": {},
   "source": [
    "[(back...)](#Pooling)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ae3579b",
   "metadata": {},
   "source": [
    "# GlobalPooling\n",
    "\n",
    "* [Global Average Pooling](#Global-Average-Pooling)\n",
    "* [Global Max Pooling](#Global-Max-Pooling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cd2f8ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.layers import (GlobalAveragePooling2D,\n",
    "                                     GlobalMaxPooling2D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "938018f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_img = np.load(\"./data/globalpooling_input.npy\")[np.newaxis, ...]\n",
    "input_img = input_img.astype('float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46eefb3f",
   "metadata": {},
   "source": [
    "* ## Global Average Pooling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8229404f",
   "metadata": {},
   "source": [
    "![](https://i.imgur.com/c62Vie8.gif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "041e6715",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(input_img.shape)\n",
    "print(input_img[..., 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71da6668",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_result = GlobalAveragePooling2D()(input_img)\n",
    "avg_result = avg_result.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "504f5335",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(avg_result.shape)\n",
    "print(avg_result.squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff242213",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_img.mean((1, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "708b0d90",
   "metadata": {},
   "source": [
    "[(back...)](#GlobalPooling)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0df804f8",
   "metadata": {},
   "source": [
    "* ## Global Max Pooling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b2e0fd2",
   "metadata": {},
   "source": [
    "![](https://i.imgur.com/XFNnWSe.gif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb522a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_result = GlobalMaxPooling2D()(input_img)\n",
    "max_result = max_result.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "551361ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(input_img.shape)\n",
    "print(input_img[..., 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d584b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(max_result.shape)\n",
    "print(max_result.squeeze())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81966ef9",
   "metadata": {},
   "source": [
    "[(back...)](#GlobalPooling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e029c10",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
